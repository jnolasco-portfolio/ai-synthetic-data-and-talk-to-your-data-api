server:
  port: 8081

spring:
  application:
    name: ai-synthetic-data-generator
  profiles:
    active: local
  liquibase:
    enabled: false

  ai:
    vertex:
      ai:
        gemini:
          project-id: ${GOOGLE_CLOUD_PROJECT}
          location: ${GOOGLE_CLOUD_LOCATION}
          chat:
            options:
              model: gemini-2.5-flash
              temperature: 0.2
    chat:
      client:
        observations:
          log-prompt: true # Include the user's prompt
          log-completion: true # Include the model's response

# 1. OpenTelemetry Configuration for Traces (Sent to Langfuse)
logging:
  level:
    org:
      springframework:
        ai: DEBUG
management:
  tracing:
    sampling:
      probability: 1.0 # Sample 100% of requests for full tracing (adjust in production as needed)
  observations:
    annotations:
      enabled: true # Enable @Observed (if you use observation annotations in code)
  exporters:
  otlphttp/langfuse:
    endpoint: "https://localhost:3001/api/public/otel" # Adjust based on your region
    headers:
      Authorization: "Basic ${LANGFUSE_OTEL_AUTH}" # Base64 encoded API keys

